{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-23T01:01:54.943202Z",
     "start_time": "2024-03-23T01:01:54.938247Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import Model\n",
    "from keras.src.applications import EfficientNetB0\n",
    "from keras.src.callbacks import EarlyStopping\n",
    "from keras.src.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from keras.src.optimizers import Adam\n",
    "from keras.src.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# One Hot encode the labels\n",
    "\n",
    "data = \"../Data/data_directory.csv\"\n",
    "\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "# Drop the rows where Grade is I\n",
    "df = df[df[\"Grade\"] != \"I\"]\n",
    "\n",
    "# 0 MEANS IT IS A, 1 MEANS IT IS B, C, or D\n",
    "df['Grade'] = df['Grade'].apply(lambda x: 0 if x == 'A' else 1)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df[\"Pixels\"] = \"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T01:01:54.965724Z",
     "start_time": "2024-03-23T01:01:54.944204Z"
    }
   },
   "id": "fd2b099803424901",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                             Image  Grade  \\\n0       a_IMAGE_001_left_ankle.jpg      1   \n1        a_IMAGE_001_left_calf.jpg      1   \n2  a_IMAGE_001_left_high_thigh.jpg      1   \n3   a_IMAGE_001_left_low_thigh.jpg      1   \n4  a_IMAGE_001_left_metatarsal.jpg      1   \n\n                                              Pixels  \n0  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  \n1  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  \n2  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  \n3  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  \n4  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Grade</th>\n      <th>Pixels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a_IMAGE_001_left_ankle.jpg</td>\n      <td>1</td>\n      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a_IMAGE_001_left_calf.jpg</td>\n      <td>1</td>\n      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a_IMAGE_001_left_high_thigh.jpg</td>\n      <td>1</td>\n      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a_IMAGE_001_left_low_thigh.jpg</td>\n      <td>1</td>\n      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a_IMAGE_001_left_metatarsal.jpg</td>\n      <td>1</td>\n      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the images into pixel values\n",
    "\n",
    "image_folder = \"../Data/data\"\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    img_path = image_folder + \"/\" + row[\"Image\"]\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.astype(np.float32)\n",
    "    df.at[index, \"Pixels\"] = img\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T01:02:08.736575Z",
     "start_time": "2024-03-23T01:01:54.966726Z"
    }
   },
   "id": "a9e9ab352b6d18b2",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "\n",
    "# Drop the Image column\n",
    "df = df.drop(columns=[\"Image\"])\n",
    "\n",
    "# Split the data\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train, val = train_test_split(train, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = np.array(train[\"Pixels\"].tolist())\n",
    "X_val = np.array(val[\"Pixels\"].tolist())\n",
    "X_test = np.array(test[\"Pixels\"].tolist())\n",
    "y_train = np.array(train[\"Grade\"].tolist())\n",
    "y_val = np.array(val[\"Grade\"].tolist())\n",
    "y_test = np.array(test[\"Grade\"].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T01:02:10.257788Z",
     "start_time": "2024-03-23T01:02:08.737577Z"
    }
   },
   "id": "fedbae2e8765b7d4",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "data_augmentation.fit(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T01:02:11.554098Z",
     "start_time": "2024-03-23T01:02:10.257788Z"
    }
   },
   "id": "75fec466d057a7c7",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "186/186 [==============================] - 645s 3s/step - loss: 0.4325 - accuracy: 0.8150 - val_loss: 0.5989 - val_accuracy: 0.6616 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "186/186 [==============================] - 606s 3s/step - loss: 0.2783 - accuracy: 0.8839 - val_loss: 0.7086 - val_accuracy: 0.6858 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "186/186 [==============================] - 586s 3s/step - loss: 0.2184 - accuracy: 0.9116 - val_loss: 0.3818 - val_accuracy: 0.8444 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "186/186 [==============================] - 580s 3s/step - loss: 0.1790 - accuracy: 0.9242 - val_loss: 0.4962 - val_accuracy: 0.8338 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "186/186 [==============================] - 578s 3s/step - loss: 0.1275 - accuracy: 0.9531 - val_loss: 0.3286 - val_accuracy: 0.8807 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "186/186 [==============================] - 612s 3s/step - loss: 0.1101 - accuracy: 0.9561 - val_loss: 0.4495 - val_accuracy: 0.8595 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "186/186 [==============================] - 672s 4s/step - loss: 0.0977 - accuracy: 0.9634 - val_loss: 0.4142 - val_accuracy: 0.8761 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "186/186 [==============================] - 604s 3s/step - loss: 0.0791 - accuracy: 0.9706 - val_loss: 0.3540 - val_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "186/186 [==============================] - 584s 3s/step - loss: 0.0664 - accuracy: 0.9753 - val_loss: 0.3874 - val_accuracy: 0.8882 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9768\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "186/186 [==============================] - 603s 3s/step - loss: 0.0605 - accuracy: 0.9768 - val_loss: 0.4666 - val_accuracy: 0.8807 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "186/186 [==============================] - 604s 3s/step - loss: 0.0492 - accuracy: 0.9812 - val_loss: 0.3979 - val_accuracy: 0.8897 - lr: 2.0000e-05\n",
      "Epoch 12/100\n",
      "186/186 [==============================] - 592s 3s/step - loss: 0.0366 - accuracy: 0.9869 - val_loss: 0.4210 - val_accuracy: 0.8807 - lr: 2.0000e-05\n",
      "Epoch 13/100\n",
      "186/186 [==============================] - 624s 3s/step - loss: 0.0370 - accuracy: 0.9872 - val_loss: 0.4155 - val_accuracy: 0.8958 - lr: 2.0000e-05\n",
      "Epoch 14/100\n",
      "186/186 [==============================] - 614s 3s/step - loss: 0.0357 - accuracy: 0.9872 - val_loss: 0.4469 - val_accuracy: 0.8792 - lr: 2.0000e-05\n",
      "Epoch 15/100\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9891\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "186/186 [==============================] - 643s 3s/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 0.4376 - val_accuracy: 0.8822 - lr: 2.0000e-05\n",
      "Epoch 16/100\n",
      "186/186 [==============================] - 705s 4s/step - loss: 0.0314 - accuracy: 0.9884 - val_loss: 0.4174 - val_accuracy: 0.8837 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "186/186 [==============================] - 804s 4s/step - loss: 0.0238 - accuracy: 0.9914 - val_loss: 0.4166 - val_accuracy: 0.8822 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "186/186 [==============================] - 692s 4s/step - loss: 0.0281 - accuracy: 0.9899 - val_loss: 0.4188 - val_accuracy: 0.8852 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "186/186 [==============================] - 685s 4s/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 0.4364 - val_accuracy: 0.8792 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "186/186 [==============================] - 686s 4s/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.4209 - val_accuracy: 0.8912 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "186/186 [==============================] - 673s 4s/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 0.4355 - val_accuracy: 0.8882 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "186/186 [==============================] - 730s 4s/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.4406 - val_accuracy: 0.8867 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9923Restoring model weights from the end of the best epoch: 13.\n",
      "186/186 [==============================] - 714s 4s/step - loss: 0.0212 - accuracy: 0.9923 - val_loss: 0.4334 - val_accuracy: 0.8912 - lr: 1.0000e-05\n",
      "Epoch 23: early stopping\n"
     ]
    }
   ],
   "source": [
    "efficient_net_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = GlobalAveragePooling2D()(efficient_net_model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=efficient_net_model.input, outputs=predictions)\n",
    "\n",
    "for layer in efficient_net_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1, min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T05:09:33.261838Z",
     "start_time": "2024-03-23T01:02:11.555100Z"
    }
   },
   "id": "f9768dda595d667a",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 37s 717ms/step - loss: 0.3959 - accuracy: 0.8869\n",
      "Test Loss: 0.3958946466445923\n",
      "Test Accuracy: 0.8869407773017883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "model_scores = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", model_scores[0])\n",
    "print(\"Test Accuracy:\", model_scores[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T05:10:12.138695Z",
     "start_time": "2024-03-23T05:09:33.292867Z"
    }
   },
   "id": "1f262f5e99226741",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 41s 789ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       975\n",
      "           1       0.87      0.86      0.86       679\n",
      "\n",
      "    accuracy                           0.89      1654\n",
      "   macro avg       0.88      0.88      0.88      1654\n",
      "weighted avg       0.89      0.89      0.89      1654\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_classes = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T05:16:42.668388Z",
     "start_time": "2024-03-23T05:16:01.075583Z"
    }
   },
   "id": "c3f219d14e9567a4",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"waveformMedModel.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T05:24:28.122272Z",
     "start_time": "2024-03-23T05:24:27.622720Z"
    }
   },
   "id": "84558f70f17fc3d5",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5c2c4c7764eac255",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
